{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7821c501-8c5d-4af6-81cd-caa6ad0bd58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "from datasets import concatenate_datasets\n",
    "from IPython.display import HTML\n",
    "\n",
    "from tqdm import tqdm\n",
    "import re \n",
    "import numpy as np\n",
    "from markdownify import markdownify as md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datafolders_name(*dataset_names):\n",
    "    l = []\n",
    "    for name in dataset_names:\n",
    "        l.append(f\"data/{name}.stackexchange.com/train-00000-of-00001.parquet\")\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dc821970-efdb-407f-bd79-59da09323280",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "topic_names = [\"philosophy\", 'philosophy.meta','buddhism','datascience']\n",
    "ds = load_dataset(\"HuggingFaceH4/stack-exchange-preferences\", split=\"train\",data_files = get_datafolders_name(*topic_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<p>Good morning everyone.</p>\\n<p>I have the following data:</p>\\n<pre><code>import pandas as pd\\n\\ninfo = {\\n'states': [-1, -1, -1, 1, 1, -1, 0, 1, 1, 1],\\n'values': [34, 29, 28, 30, 35, 33, 33, 36, 40, 41] }\\n\\ndf = pd.DataFrame(data=info)\\n\\nprint(df)\\n\\n&gt;&gt;&gt; \\n    states   values\\n0       -1       34\\n1       -1       29\\n2       -1       28\\n3        1       30\\n4        1       35\\n5       -1       33\\n6        0       33\\n7        1       36\\n8        1       40\\n9        1       41\\n</code></pre>\\n<p>I need to group the data <strong>using PANDAS</strong> (and/or higher order functions) (<em>already did the exercise using for loops</em>), I need to group the data having the &quot;states&quot; column as a guide. But the grouping should not be of all the data, I only need to group the data that is neighboring... as follows:</p>\\n<p>Initial DataFrame:</p>\\n<pre><code>    states   values\\n0       -1       34 ┐\\n1       -1       29 │    Group this part (states = -1)\\n2       -1       28 ┘\\n3        1       30 ┐    Group this part (states =  1)\\n4        1       35 ┘\\n5       -1       33     'Group' this part (states = -1)\\n6        0       33     'Group' this part (states =  0)\\n7        1       36 ┐\\n8        1       40 │    Group this part (states =  1)\\n9        1       41 ┘\\n</code></pre>\\n<p>It would result in a DataFrame, with a grouping by segments (from the &quot;states&quot; column) and in another column the sum of the data (from the &quot;values&quot; column).</p>\\n<p>Expected DataFrame:</p>\\n<pre><code>    states   values\\n0       -1       91     (values=34+29+28)\\n1        1       65     (values=30+35)\\n2       -1       33\\n3        0       33\\n4        1       117    (values=36+40+41)\\n</code></pre>\\n<p>You who are more versed in these issues, perhaps you can help me perform this operation.</p>\\n<p><em><strong>Thank you so much!</strong></em></p>\\n\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['question'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0d8d8729-6d6b-4791-a24a-cb112c399bd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>What would it mean to say that mathematics was invented and how would this be different from saying mathematics was discovered? </p>\n",
       "\n",
       "<p>Is this even a serious philosophical question or just a meaningless/tautological linguistic ambiguity?</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(ds[0][\"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b3b60caa-3bd9-4033-ab1c-90c5b08ef3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lang_callback(el):\n",
    "    lang = el['class'][0] if el.has_attr('class') else None\n",
    "    \n",
    "    if not lang is None:\n",
    "        lang = lang.split(\"-\")[-1]\n",
    "    return lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de1123a0-7468-4d13-a8d3-4011ace36c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def html2md(text):\n",
    "    text = md(text, code_language_callback=lang_callback)\n",
    "    text = re.sub(r\"\\n\\s*\\n\", \"\\n\\n\", text).strip()\n",
    "    return text.encode('utf-8', 'replace').decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9da64a0-c753-4d35-9369-b70a7a9fa2f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What would it mean to say that mathematics was invented and how would this be different from saying mathematics was discovered? \n",
      "\n",
      "Is this even a serious philosophical question or just a meaningless/tautological linguistic ambiguity?\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    text = html2md(ds[i][\"question\"])\n",
    "    print(text)\n",
    "    print(\"==\"*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bf33a2f-fed5-49e7-8046-e813ad172b17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.9874"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([len(ds[i][\"answers\"])*(len(ds[i][\"answers\"])-1)/2 for i in range(10000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25877"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "88ea2dd5-b885-4f65-bae3-1319c7816044",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.shuffle(seed=42)\n",
    "index = list(range(len(ds)))\n",
    "\n",
    "ds_splits = DatasetDict({\n",
    "    \"finetune\": ds.select(index[:len(ds)*3//10]),\n",
    "    \"reward\": ds.select(index[len(ds)*3//10:len(ds)*6//10]),\n",
    "    \"rl\": ds.select(index[len(ds)*6//10:len(ds)*9//10]),\n",
    "    \"evaluation\": ds.select(index[len(ds)*9//10:]),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1607922d-f585-4de7-be70-2205b5170102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    finetune: Dataset({\n",
       "        features: ['qid', 'question', 'answers', 'date', 'metadata'],\n",
       "        num_rows: 7763\n",
       "    })\n",
       "    reward: Dataset({\n",
       "        features: ['qid', 'question', 'answers', 'date', 'metadata'],\n",
       "        num_rows: 7763\n",
       "    })\n",
       "    rl: Dataset({\n",
       "        features: ['qid', 'question', 'answers', 'date', 'metadata'],\n",
       "        num_rows: 7763\n",
       "    })\n",
       "    evaluation: Dataset({\n",
       "        features: ['qid', 'question', 'answers', 'date', 'metadata'],\n",
       "        num_rows: 2588\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "edc8af18-94a5-49e9-ae73-ce4ba81d9739",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_comparison(answers):\n",
    "    \"\"\"Returns tuples of answers, first always best\"\"\"\n",
    "    pairs = []\n",
    "    \n",
    "    for i in range(len(answers)-1):\n",
    "        for j in range(i+1, len(answers)):\n",
    "            if answers[i][\"pm_score\"]>answers[j][\"pm_score\"]:\n",
    "                pairs.append((answers[i][\"text\"], answers[j][\"text\"]))\n",
    "            elif answers[i][\"pm_score\"]<answers[j][\"pm_score\"]:\n",
    "                pairs.append((answers[j][\"text\"], answers[i][\"text\"]))\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "88afe90e-364e-4b21-898b-1c6ceb9cfd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(examples):\n",
    "    \"\"\"Cleans HTML and returns paired answers (j is better than k). Note that this returns more examples (one for each pair per question).\"\"\"\n",
    "    \n",
    "    MAX_PAIRS_PER_QUESTION = 10\n",
    "    n_samples = len(examples[\"qid\"])\n",
    "    \n",
    "    # initialize empty lists for new samples\n",
    "    new_examples = {\"question\": [], \"response_j\": [], \"response_k\": []}\n",
    "    for key in examples:\n",
    "        new_examples[key] = []\n",
    "    \n",
    "    for sample_id in range(n_samples):\n",
    "        # get pairs where first is always the better one\n",
    "        pairs = binary_comparison(examples[\"answers\"][sample_id])\n",
    "        n_answers = len(examples[\"answers\"][sample_id])\n",
    "        \n",
    "        # sample if we get more pairs than maximum\n",
    "        if len(pairs) > MAX_PAIRS_PER_QUESTION:\n",
    "            indices = np.random.choice(list(range(len(pairs))), MAX_PAIRS_PER_QUESTION, replace=False)\n",
    "            pairs = [pairs[i] for i in indices]\n",
    "        \n",
    "        # construct the samples\n",
    "        for pair in pairs:\n",
    "            for key in examples:\n",
    "                if key==\"question\":\n",
    "                    new_examples[key].append(html2md(examples[key][sample_id]))\n",
    "                else:\n",
    "                    new_examples[key].append(examples[key][sample_id])\n",
    "            new_examples[\"response_j\"].append(html2md(pair[0]))\n",
    "            new_examples[\"response_k\"].append(html2md(pair[1]))\n",
    "    return new_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ac06aac5-3953-4321-9f1e-6ff210bee82d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b6b738cdb5147528148e10253f496e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=9):   0%|          | 0/7763 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by mode='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dde66658cca4f12b6811da145b0b47b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=9):   0%|          | 0/7763 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "308b81c83e6c45819daeeb3b58ef6b40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=9):   0%|          | 0/7763 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fffd8e1831245d4beaf7c49dd7e0bd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=9):   0%|          | 0/2588 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds_result = ds_splits.map(preprocess, batch_size=1000, batched=True, num_proc=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "06e3d891-ffde-4762-95d5-39658a1127ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    finetune: Dataset({\n",
       "        features: ['qid', 'question', 'answers', 'date', 'metadata', 'response_j', 'response_k'],\n",
       "        num_rows: 25152\n",
       "    })\n",
       "    reward: Dataset({\n",
       "        features: ['qid', 'question', 'answers', 'date', 'metadata', 'response_j', 'response_k'],\n",
       "        num_rows: 25704\n",
       "    })\n",
       "    rl: Dataset({\n",
       "        features: ['qid', 'question', 'answers', 'date', 'metadata', 'response_j', 'response_k'],\n",
       "        num_rows: 25488\n",
       "    })\n",
       "    evaluation: Dataset({\n",
       "        features: ['qid', 'question', 'answers', 'date', 'metadata', 'response_j', 'response_k'],\n",
       "        num_rows: 8354\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "631416dc-cf19-485d-a2f3-94c9b2cb2bfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'qid': 22075,\n",
       " 'question': 'Though to the extent of my admittedly scarce knowledge, decapitation as a simile for some level of attainment is not to be found in the Pali Canon, but I bet the Zen tradition offers countless koans and stories wherein, figuratively, the incumbent experiencer of realization is beheaded, very much to his surprise I would say.\\n\\nIf you happen to know a few of these stories, your kind attention in helping me digging out these similes is greatly appreciated.\\n\\nMy gratitude for having taken the time to read this.',\n",
       " 'answers': [{'answer_id': 22083,\n",
       "   'author': 'Bonn',\n",
       "   'author_id': 10100,\n",
       "   'author_profile': 'https://buddhism.stackexchange.com/users/10100',\n",
       "   'pm_score': 0,\n",
       "   'selected': False,\n",
       "   'text': '<p>This is picture that show consciousness\\'s arising one by one (consciousness can  arise just one per time per person.)</p>\\n\\n<p>Javana is Pr to Jh in the below picture.</p>\\n\\n<p>When bhavaṅga vanish, then manodvāra arise. When manodvāra vanish, then parikamma javana arise. When Pr javana vanish, then Up javana arise. When Up javana vanish, then An javana arise. When An javana vanish, then Go javana arise. <strong>When Go javana vanish, then Jh javana arise. When Jh javana vanish, Next Jh javana arise. Infinite Jhāna javana arise until jhāna will stop.</strong></p>\\n\\n<p><strong>Parikamma</strong> is practicing consciousness. <strong>Upacāra</strong> is up level of parikamma. If Upacāra can up level enough to change to be appanā-jhāna, then gotrabhū will arise to prepare for jhāna. The arising step of consciousness will be as alike as the below picture.</p>\\n\\n<p><strong>But if Upacāra can not upgrade to jhāna level</strong>,  1 parikamma javana arise then 6 Upacāra javana arise, step by step. Then bhavaṅga arise, infinity. Then loop again. In pali canon, teachers just called them the same as \"javana\", because no arising of jhāna-consciousness, equal to nothing.</p>\\n\\n<p><strong>This loop will be Upacāra-samadhi when the practitioner has not any unwholesome loops arise between  the wholesome loops.</strong> If just one unwholesome loop arise, the practitioner still being at khanika-samādhi level.</p>\\n\\n<p><a href=\"https://i.stack.imgur.com/yIYsT.jpg\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/yIYsT.jpg\" alt=\"enter image description here\"></a></p>\\n\\n<p>Cr. <a href=\"http://www.houstonmeditationc.com/?q=node/65#_Toc471645999\" rel=\"nofollow noreferrer\">http://www.houstonmeditationc.com/?q=node/65#_Toc471645999</a></p>\\n'},\n",
       "  {'answer_id': 22866,\n",
       "   'author': 'Community',\n",
       "   'author_id': -1,\n",
       "   'author_profile': 'https://buddhism.stackexchange.com/users/-1',\n",
       "   'pm_score': 1,\n",
       "   'selected': False,\n",
       "   'text': '<p>I would say that this word has been conflated and in my experience unnecessary for entering jhana. please refer to the instructions on how to enter jhana found in the Sutta Pitaka. </p>\\n'}],\n",
       " 'date': '2017/08/14',\n",
       " 'metadata': ['https://buddhism.stackexchange.com/questions/22075',\n",
       "  'https://buddhism.stackexchange.com',\n",
       "  'https://buddhism.stackexchange.com/users/11288/'],\n",
       " 'response_j': 'I would say that this word has been conflated and in my experience unnecessary for entering jhana. please refer to the instructions on how to enter jhana found in the Sutta Pitaka.',\n",
       " 'response_k': 'This is picture that show consciousness\\'s arising one by one (consciousness can arise just one per time per person.)\\n\\nJavana is Pr to Jh in the below picture.\\n\\nWhen bhavaṅga vanish, then manodvāra arise. When manodvāra vanish, then parikamma javana arise. When Pr javana vanish, then Up javana arise. When Up javana vanish, then An javana arise. When An javana vanish, then Go javana arise. **When Go javana vanish, then Jh javana arise. When Jh javana vanish, Next Jh javana arise. Infinite Jhāna javana arise until jhāna will stop.**\\n\\n**Parikamma** is practicing consciousness. **Upacāra** is up level of parikamma. If Upacāra can up level enough to change to be appanā-jhāna, then gotrabhū will arise to prepare for jhāna. The arising step of consciousness will be as alike as the below picture.\\n\\n**But if Upacāra can not upgrade to jhāna level**, 1 parikamma javana arise then 6 Upacāra javana arise, step by step. Then bhavaṅga arise, infinity. Then loop again. In pali canon, teachers just called them the same as \"javana\", because no arising of jhāna-consciousness, equal to nothing.\\n\\n**This loop will be Upacāra-samadhi when the practitioner has not any unwholesome loops arise between the wholesome loops.** If just one unwholesome loop arise, the practitioner still being at khanika-samādhi level.\\n\\n[![enter image description here](https://i.stack.imgur.com/yIYsT.jpg)](https://i.stack.imgur.com/yIYsT.jpg)\\n\\nCr. <http://www.houstonmeditationc.com/?q=node/65#_Toc471645999>'}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_result[\"finetune\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2c96653b-7a5a-4cae-a327-b6aa77aa5850",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_result = ds_result.remove_columns([\"answers\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "15c2e5ee-7c7d-4e98-9e63-e5d37a9354aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    finetune: Dataset({\n",
       "        features: ['qid', 'question', 'date', 'metadata', 'response_j', 'response_k'],\n",
       "        num_rows: 25152\n",
       "    })\n",
       "    reward: Dataset({\n",
       "        features: ['qid', 'question', 'date', 'metadata', 'response_j', 'response_k'],\n",
       "        num_rows: 25704\n",
       "    })\n",
       "    rl: Dataset({\n",
       "        features: ['qid', 'question', 'date', 'metadata', 'response_j', 'response_k'],\n",
       "        num_rows: 25488\n",
       "    })\n",
       "    evaluation: Dataset({\n",
       "        features: ['qid', 'question', 'date', 'metadata', 'response_j', 'response_k'],\n",
       "        num_rows: 8354\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4d42b35c-5252-4b49-ba4b-20818bc9e086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finetune\n",
      "reward\n",
      "rl\n",
      "evaluation\n"
     ]
    }
   ],
   "source": [
    "for key in ds_result:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e32c11d7-a88e-4d92-9dfc-92b2a67c5455",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm\n",
    "\n",
    "from huggingface_hub import Repository\n",
    "\n",
    "\n",
    "def save_shard(shard_tuple):\n",
    "    \"\"\"Save shard\"\"\"\n",
    "    filename, shard = shard_tuple\n",
    "    # use to_json instead to save as json file\n",
    "    shard.to_parquet(filename)\n",
    "\n",
    "\n",
    "def save_manual_shards(ds, user=\"TommyBark\", remote_dataset_repo=\"stack-exchange-paired_micro\", subfolder=\"train\"):\n",
    "    \"\"\"Save sharded data\n",
    "    Args:\n",
    "        ds (Dataset): dataset to be saved\n",
    "        user (str): user name\n",
    "        remote_dataset_repo (str): remote dataset repository\n",
    "        out_path (str): path to save the shards\"\"\"\n",
    "    # this will create a folder OUT_PATH that is a clone of REMOTE_DATASET_REPO\n",
    "    # you can save the shards inside it and do git add/commit/push to push data to the hub\n",
    "    out_path = remote_dataset_repo\n",
    "    # if out path doesnt already exist\n",
    "    if not os.path.exists(out_path):\n",
    "        repo = Repository(\n",
    "            local_dir=out_path,\n",
    "            clone_from=user + \"/\" + remote_dataset_repo,\n",
    "            repo_type=\"dataset\",\n",
    "            use_auth_token=True,\n",
    "            git_user=user,\n",
    "        )\n",
    "\n",
    "    # files will be numerous we save them in a folder called data inside out_path\n",
    "    if not os.path.exists(out_path + \"/data\"):\n",
    "        os.mkdir(out_path + \"/data\")\n",
    "    os.mkdir(out_path + f\"/data/{subfolder}\")\n",
    "    \n",
    "    SHARD_SIZE = 1000 << 20\n",
    "    if ds._indices is not None:\n",
    "        dataset_nbytes = ds.data.nbytes * len(ds._indices) / len(ds.data)\n",
    "    else:\n",
    "        dataset_nbytes = ds.data.nbytes\n",
    "    num_shards = int(dataset_nbytes / SHARD_SIZE) + 1\n",
    "    print(f\"Number of shards: {num_shards}\")\n",
    "\n",
    "    print(\"sharding the dataset\")\n",
    "    t_start = time.time()\n",
    "    shards = (\n",
    "        ds.shard(num_shards=num_shards, index=i, contiguous=True)\n",
    "        for i in range(num_shards)\n",
    "    )\n",
    "    # use f\"{OUT_PATH}/data/train-{index:05d}-of-{num_shards:05d}.json\" instead for json files\n",
    "    filenames = (\n",
    "        f\"{out_path}/data/{subfolder}/train-{index:05d}-of-{num_shards:05d}.parquet\"\n",
    "        for index in range(num_shards)\n",
    "    )\n",
    "\n",
    "    with Pool(16) as p:\n",
    "        list(\n",
    "            tqdm(\n",
    "                p.imap_unordered(save_shard, zip(filenames, shards), chunksize=4),\n",
    "                total=num_shards,\n",
    "            )\n",
    "        )\n",
    "    print(f\"Time to save dataset: {time.time()-t_start:.2f}\")\n",
    "    # to push dataset to hub do: git add/commit/push inside OUT_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a90664eb-5c54-4fae-9a8a-d509bb2abdfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of shards: 1\n",
      "sharding the dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/datasets/table.py:1387: FutureWarning: promote has been superseded by mode='default'.\n",
      "  return cls._concat_blocks(pa_tables_to_concat_vertically, axis=0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c2ff3d36e3d43f48303698a7c72cd2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/26 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to save dataset: 0.74\n",
      "Number of shards: 1\n",
      "sharding the dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/datasets/table.py:1387: FutureWarning: promote has been superseded by mode='default'.\n",
      "  return cls._concat_blocks(pa_tables_to_concat_vertically, axis=0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a26575e31d24dc9a865f5f0d856bf6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/26 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to save dataset: 0.72\n",
      "Number of shards: 1\n",
      "sharding the dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/datasets/table.py:1387: FutureWarning: promote has been superseded by mode='default'.\n",
      "  return cls._concat_blocks(pa_tables_to_concat_vertically, axis=0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e0923a3925d495384c616d13150523c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/26 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to save dataset: 0.86\n",
      "Number of shards: 1\n",
      "sharding the dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/datasets/table.py:1387: FutureWarning: promote has been superseded by mode='default'.\n",
      "  return cls._concat_blocks(pa_tables_to_concat_vertically, axis=0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36b8e768bf314dbdaa08c40cd5e5f813",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/9 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to save dataset: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for key in ds_result:\n",
    "    save_manual_shards(ds_result[key], subfolder=key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62f5a7f-2a23-4e0d-9e49-b29f88ea8c13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
